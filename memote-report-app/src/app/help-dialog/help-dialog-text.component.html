<h2 mat-dialog-title>Help</h2>
<mat-dialog-content>
    <mat-card>
    <mat-card-title>What do the colours mean?</mat-card-title>
    <mat-card-content>
    <h4>Snapshot Report</h4>
    Results without highlights are kept in the main
        <span style="color: rgb(42, 123, 184)"> <b> blue </b> </span> 
        colour of the memote colour scheme. Scored results will be marked with a gradient ranging from 
        <span style="color: rgb(161, 18, 18)"> <b> red </b> </span> to 
        <span style="color: rgb(18, 161, 46)"> <b> green </b> </span> denoting a low or a high score respectively:
        <div fxLayoutAlign='center center'>
            <span> <b>0%</b></span>
            <div style="display: inline-block; vertical-align: middle">
                <svg width="120" height="60">
                    <defs>
                        <linearGradient id="grad1">
                        <stop offset="0%" style="stop-color:rgb(161, 18, 18);stop-opacity:1" />
                                <stop offset="100%" style="stop-color:rgb(18, 161, 46);stop-opacity:1" />
                        </linearGradient>
                    </defs>
                    <rect fill="url(#grad1)"
                        x="10" y="10" width="100" height="100"/>
                </svg>
            </div>     
        <span> <b>100% </b></span>
        </div>
        <h4>Diff Report</h4>
        The colour in the Diff Report depends on the ratio of the sample minimum to the sample maxium. 
        Result sets where the sample minimum and the sample maximum are identical will be coloured in the main
        <span style="color: rgb(42, 123, 184)"> <b> blue </b> </span> 
        colour of the memote colour scheme. Result sets where the sample minimum is very small relative to the sample maximum will appear
        <span style="color: rgb(161, 18, 18)"> <b> red </b> </span>. 
        This ratio is calculated with the following formula:
        <br>
        <b> 1 - (Min / Max)) * 100 </b>
        This is then mapped to the following gradient:
        <div fxLayoutAlign='center center'>
            <span> <b>Identical</b></span>
            <div style="display: inline-block; vertical-align: middle">
                <svg width="120" height="60">
                    <defs>
                        <linearGradient id="grad2">
                        <stop offset="0%" style="stop-color:rgb(42, 123, 184);stop-opacity:1" />
                        <stop offset="100%" style="stop-color:rgb(161, 18, 18);stop-opacity:1" />
                        </linearGradient>
                    </defs>
                    <rect fill="url(#grad2)"
                        x="10" y="10" width="100" height="100"/>
                </svg>
            </div>     
        <span> <b>Different</b></span>
        </div>
    </mat-card-content>
    </mat-card>
    <mat-card>
        <mat-card-title>Why are there two principal test categories?</mat-card-title>
        <mat-card-content>
    <p>The tests in the scored section are independent of the type of the modeled organism, the complexity of the model itself or the types of identifiers
         that are used to describe the model components. Calculating a score for these tests allows for the quick comparison of any two given models at a
          glance. The unscored section provides general statistics and covers specific aspects of a model that are not universally applicable. For instance,
           dedicated quality control of the biomass equation only applies to metabolic models which are used to investigate cell growth.</p>
    <p>The variety of constraints-based modeling approaches and the fundamental differences between various organisms compound the assessment of GEMs. For
         instance, authors may publish metabolic networks, which are constrained to reflect one experimental condition or publish unconstrained metabolic
          databases, which need to be initialized before simulation. Both can be encoded in SBML. With having a scored test section, we attempt to normalize
           each type of model such that they become comparable.</p>
        </mat-card-content>
    </mat-card>
    <mat-card>
    <mat-card-title>How is the score calculated?</mat-card-title>
    <mat-card-content>
    <p>Each test provides a relative measure of completeness with regard to the tested property. The final score is the weighted sum of all individual test
         results normalized by the maximally achievable score i.e. all individual results at 100%. Individual tests can be weighted, but it is also possible to apply weighting to entire test 
         categories. Hence the final score is calculated:</p>
         <br>
         <b> FinalScore = Sum( a * Section1Sum( w1 * Test1, w2 * Test2 ), b * Section2Sum( w3 * Test3, w4 * Test4 )) / MaxScore </b>
    <p> <b>a, b</b> denote section weights, <b>w1, w2, w3, w4</b> denote weights applied to individual tests.</p>
    </mat-card-content>
    </mat-card>
</mat-dialog-content>
<mat-dialog-actions>
        <button mat-button mat-dialog-close>Close</button>
</mat-dialog-actions>